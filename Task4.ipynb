{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8323539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklearn.metrics import (mean_squared_error, r2_score, roc_auc_score, \n",
    "                           accuracy_score, classification_report, make_scorer)\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from scipy.stats import randint, uniform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed75fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "try:\n",
    "    df = pd.read_csv('file.csv')\n",
    "    print(\"Data loaded successfully. Shape:\", df.shape)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Cleaning and Preparation --------------------------------------------\n",
    "\n",
    "def clean_and_prepare_data(df):\n",
    "    \"\"\"Clean data and remove specified columns\"\"\"\n",
    "    # Remove specified columns\n",
    "    columns_to_drop = ['CrossBorder', 'Citizenship', 'MaritalStatus', \n",
    "                      'CustomValueEstimate', 'NumberOfVehiclesInFleet']\n",
    "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "    \n",
    "    # Create claim indicator if not exists\n",
    "    if 'HasClaim' not in df.columns:\n",
    "        df['HasClaim'] = (df['TotalClaims'] > 0).astype(int)\n",
    "    \n",
    "    # Convert known numeric columns\n",
    "    numeric_cols = ['TotalClaims', 'CalculatedPremiumPerTerm', 'SumInsured', \n",
    "                   'RegistrationYear', 'Cylinders', 'cubiccapacity', 'kilowatts',\n",
    "                   'NumberOfDoors', 'CapitalOutstanding', 'VehicleAge']\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    # Convert categorical columns to strings\n",
    "    categorical_cols = ['IsVATRegistered', 'LegalType', 'Title',\n",
    "                       'Language', 'Bank', 'AccountType', 'Gender',\n",
    "                       'Country', 'Province', 'PostalCode', 'MainCrestaZone',\n",
    "                       'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType',\n",
    "                       'make', 'Model', 'bodytype', 'AlarmImmobiliser', 'TrackingDevice',\n",
    "                       'NewVehicle', 'WrittenOff', 'Rebuilt', 'Converted',\n",
    "                       'TermFrequency', 'ExcessSelected', 'CoverCategory', 'CoverType',\n",
    "                       'CoverGroup', 'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "    \n",
    "    # Feature engineering\n",
    "    current_year = pd.Timestamp.now().year\n",
    "    if 'RegistrationYear' in df.columns:\n",
    "        df['VehicleAge'] = current_year - df['RegistrationYear']\n",
    "    if all(col in df.columns for col in ['CalculatedPremiumPerTerm', 'SumInsured']):\n",
    "        df['PremiumToSumInsuredRatio'] = df['CalculatedPremiumPerTerm'] / df['SumInsured']\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = clean_and_prepare_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1cf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define Features and Targets ----------------------------------------------\n",
    "\n",
    "non_features = ['PolicyID', 'UnderwrittenCoverID', 'TransactionMonth', \n",
    "               'TotalClaims', 'CalculatedPremiumPerTerm', 'HasClaim']\n",
    "features = [col for col in df.columns if col not in non_features]\n",
    "\n",
    "# Separate numeric and categorical features\n",
    "numeric_features = df[features].select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = df[features].select_dtypes(include=['object', 'string']).columns.tolist()\n",
    "\n",
    "print(\"Numeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Preprocessing Pipeline --------------------------------------------------\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b84eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameter Grids for Tuning ----------------------------------------------\n",
    "\n",
    "xgb_reg_params = {\n",
    "    'regressor__n_estimators': randint(100, 500),\n",
    "    'regressor__max_depth': randint(3, 10),\n",
    "    'regressor__learning_rate': uniform(0.01, 0.3),\n",
    "    'regressor__subsample': uniform(0.6, 0.4),\n",
    "    'regressor__colsample_bytree': uniform(0.6, 0.4),\n",
    "    'regressor__gamma': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "rf_reg_params = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [None, 5, 10, 15],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "xgb_clf_params = {\n",
    "    'classifier__n_estimators': randint(100, 500),\n",
    "    'classifier__max_depth': randint(3, 10),\n",
    "    'classifier__learning_rate': uniform(0.01, 0.3),\n",
    "    'classifier__subsample': uniform(0.6, 0.4),\n",
    "    'classifier__colsample_bytree': uniform(0.6, 0.4),\n",
    "    'classifier__gamma': uniform(0, 0.5)\n",
    "}\n",
    "\n",
    "rf_clf_params = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 5, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5de1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model 1: Claim Severity Prediction with Tuning --------------------------\n",
    "\n",
    "print(\"\\n=== Claim Severity Model (Policies with Claims) ===\")\n",
    "df_claims = df[df['HasClaim'] == 1].copy()\n",
    "\n",
    "if len(df_claims) > 10:\n",
    "    X_sev = df_claims[features]\n",
    "    y_sev = df_claims['TotalClaims']\n",
    "    \n",
    "    X_train_sev, X_test_sev, y_train_sev, y_test_sev = train_test_split(\n",
    "        X_sev, y_sev, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Linear Regression (no tuning needed)\n",
    "    lr_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LinearRegression())])\n",
    "    lr_model.fit(X_train_sev, y_train_sev)\n",
    "    y_pred_lr = lr_model.predict(X_test_sev)\n",
    "    rmse_lr = np.sqrt(mean_squared_error(y_test_sev, y_pred_lr))\n",
    "    r2_lr = r2_score(y_test_sev, y_pred_lr)\n",
    "    \n",
    "    # Random Forest with GridSearch\n",
    "    rf_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(random_state=42))])\n",
    "    \n",
    "    rf_search = RandomizedSearchCV(\n",
    "        rf_model, rf_reg_params, n_iter=20, cv=3, \n",
    "        scoring='neg_root_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "    rf_search.fit(X_train_sev, y_train_sev)\n",
    "    y_pred_rf = rf_search.predict(X_test_sev)\n",
    "    rmse_rf = np.sqrt(mean_squared_error(y_test_sev, y_pred_rf))\n",
    "    r2_rf = r2_score(y_test_sev, y_pred_rf)\n",
    "    \n",
    "    # XGBoost with RandomizedSearch\n",
    "    xgb_model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', XGBRegressor(random_state=42))])\n",
    "    \n",
    "    xgb_search = RandomizedSearchCV(\n",
    "        xgb_model, xgb_reg_params, n_iter=50, cv=3, \n",
    "        scoring='neg_root_mean_squared_error', random_state=42, n_jobs=-1)\n",
    "    xgb_search.fit(X_train_sev, y_train_sev)\n",
    "    y_pred_xgb = xgb_search.predict(X_test_sev)\n",
    "    rmse_xgb = np.sqrt(mean_squared_error(y_test_sev, y_pred_xgb))\n",
    "    r2_xgb = r2_score(y_test_sev, y_pred_xgb)\n",
    "    \n",
    "    results_sev = {\n",
    "        'Linear Regression': {'RMSE': rmse_lr, 'R2': r2_lr},\n",
    "        'Random Forest': {'RMSE': rmse_rf, 'R2': r2_rf, 'best_params': rf_search.best_params_},\n",
    "        'XGBoost': {'RMSE': rmse_xgb, 'R2': r2_xgb, 'best_params': xgb_search.best_params_}\n",
    "    }\n",
    "    \n",
    "    print(\"\\nModel Performance:\")\n",
    "    for name, metrics in results_sev.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"RMSE = {metrics['RMSE']:.2f}, R2 = {metrics['R2']:.4f}\")\n",
    "        if 'best_params' in metrics:\n",
    "            print(\"Best Parameters:\")\n",
    "            for param, value in metrics['best_params'].items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "else:\n",
    "    print(f\"Not enough claims ({len(df_claims)}) to build severity model\")\n",
    "    results_sev = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236decf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model 2: Claim Probability Prediction with Tuning -----------------------\n",
    "\n",
    "print(\"\\n=== Claim Probability Model ===\")\n",
    "X_prob = df[features]\n",
    "y_prob = df['HasClaim']\n",
    "\n",
    "X_train_prob, X_test_prob, y_train_prob, y_test_prob = train_test_split(\n",
    "    X_prob, y_prob, test_size=0.2, random_state=42, stratify=y_prob)\n",
    "\n",
    "# Handle class imbalance\n",
    "if len(y_train_prob) > 0:\n",
    "    class_ratio = (len(y_train_prob) - sum(y_train_prob)) / max(1, sum(y_train_prob))\n",
    "else:\n",
    "    class_ratio = 1\n",
    "\n",
    "# Random Forest with GridSearch\n",
    "rf_clf_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, class_weight='balanced'))])\n",
    "\n",
    "rf_clf_search = RandomizedSearchCV(\n",
    "    rf_clf_model, rf_clf_params, n_iter=20, cv=3, \n",
    "    scoring='roc_auc', random_state=42, n_jobs=-1)\n",
    "rf_clf_search.fit(X_train_prob, y_train_prob)\n",
    "y_pred_rf = rf_clf_search.predict_proba(X_test_prob)[:, 1]\n",
    "auc_rf = roc_auc_score(y_test_prob, y_pred_rf)\n",
    "accuracy_rf = accuracy_score(y_test_prob, (y_pred_rf > 0.5).astype(int))\n",
    "\n",
    "# XGBoost with RandomizedSearch\n",
    "xgb_clf_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42, \n",
    "                                objective='binary:logistic',\n",
    "                                scale_pos_weight=class_ratio))])\n",
    "\n",
    "xgb_clf_search = RandomizedSearchCV(\n",
    "    xgb_clf_model, xgb_clf_params, n_iter=50, cv=3, \n",
    "    scoring='roc_auc', random_state=42, n_jobs=-1)\n",
    "xgb_clf_search.fit(X_train_prob, y_train_prob)\n",
    "y_pred_xgb = xgb_clf_search.predict_proba(X_test_prob)[:, 1]\n",
    "auc_xgb = roc_auc_score(y_test_prob, y_pred_xgb)\n",
    "accuracy_xgb = accuracy_score(y_test_prob, (y_pred_xgb > 0.5).astype(int))\n",
    "\n",
    "results_prob = {\n",
    "    'Random Forest': {\n",
    "        'AUC': auc_rf, \n",
    "        'Accuracy': accuracy_rf,\n",
    "        'best_params': rf_clf_search.best_params_\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'AUC': auc_xgb, \n",
    "        'Accuracy': accuracy_xgb,\n",
    "        'best_params': xgb_clf_search.best_params_\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nModel Performance:\")\n",
    "for name, metrics in results_prob.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"AUC = {metrics['AUC']:.4f}, Accuracy = {metrics['Accuracy']:.4f}\")\n",
    "    print(\"Best Parameters:\")\n",
    "    for param, value in metrics['best_params'].items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(\"Classification Report:\")\n",
    "    y_pred = (metrics['AUC'] > 0.5).astype(int)\n",
    "    print(classification_report(y_test_prob, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfbe797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Premium Optimization ----------------------------------------------------\n",
    "\n",
    "if results_sev and results_prob:\n",
    "    print(\"\\n=== Premium Optimization ===\")\n",
    "    try:\n",
    "        best_sev_model = xgb_search.best_estimator_ if 'XGBoost' in results_sev else rf_search.best_estimator_\n",
    "        best_prob_model = xgb_clf_search.best_estimator_ if 'XGBoost' in results_prob else rf_clf_search.best_estimator_\n",
    "        \n",
    "        prob_claims = best_prob_model.predict_proba(X_test_prob)[:, 1]\n",
    "        sev_claims = best_sev_model.predict(X_test_prob)\n",
    "        \n",
    "        risk_based_premium = prob_claims * sev_claims\n",
    "        expense_loading = 0.2  # 20% for expenses\n",
    "        profit_margin = 0.1    # 10% profit\n",
    "        risk_based_premium = risk_based_premium * (1 + expense_loading + profit_margin)\n",
    "        \n",
    "        comparison = pd.DataFrame({\n",
    "            'Actual Premium': df.loc[X_test_prob.index, 'CalculatedPremiumPerTerm'],\n",
    "            'Risk-Based Premium': risk_based_premium\n",
    "        }).dropna()\n",
    "        \n",
    "        if len(comparison) > 0:\n",
    "            print(\"\\nPremium Comparison (Sample):\")\n",
    "            print(comparison.sample(min(5, len(comparison))))\n",
    "            corr = comparison.corr().iloc[0,1]\n",
    "            print(f\"\\nCorrelation: {corr:.3f}\")\n",
    "        else:\n",
    "            print(\"No valid premium comparisons available\")\n",
    "    except Exception as e:\n",
    "        print(f\"Premium optimization error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516bb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Importance ------------------------------------------------------\n",
    "\n",
    "print(\"\\n=== Feature Importance ===\")\n",
    "try:\n",
    "    preprocessor.fit(X_train_prob)\n",
    "    numeric_feature_names = numeric_features\n",
    "    categorical_feature_names = list(\n",
    "        preprocessor.named_transformers_['cat']\n",
    "        .named_steps['onehot']\n",
    "        .get_feature_names_out(categorical_features))\n",
    "    all_feature_names = numeric_feature_names + categorical_feature_names\n",
    "    \n",
    "    if 'XGBoost' in results_prob:\n",
    "        xgb_classifier = xgb_clf_search.best_estimator_.named_steps['classifier']\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        explainer = shap.TreeExplainer(xgb_classifier)\n",
    "        shap_values = explainer.shap_values(preprocessor.transform(X_train_prob))\n",
    "        shap.summary_plot(shap_values, \n",
    "                         preprocessor.transform(X_train_prob), \n",
    "                         feature_names=all_feature_names,\n",
    "                         plot_type='bar',\n",
    "                         show=False)\n",
    "        plt.title(\"Claim Probability - Feature Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if 'XGBoost' in results_sev:\n",
    "        xgb_regressor = xgb_search.best_estimator_.named_steps['regressor']\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        explainer = shap.TreeExplainer(xgb_regressor)\n",
    "        shap_values = explainer.shap_values(preprocessor.transform(X_train_sev))\n",
    "        shap.summary_plot(shap_values, \n",
    "                         preprocessor.transform(X_train_sev), \n",
    "                         feature_names=all_feature_names,\n",
    "                         plot_type='bar',\n",
    "                         show=False)\n",
    "        plt.title(\"Claim Severity - Feature Importance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Feature importance error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933cccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final Report ------------------------------------------------------------\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "if results_sev:\n",
    "    print(\"\\nClaim Severity Models:\")\n",
    "    for name, metrics in results_sev.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"RMSE = {metrics['RMSE']:.2f}, R2 = {metrics['R2']:.4f}\")\n",
    "        if 'best_params' in metrics:\n",
    "            print(\"Best Parameters:\")\n",
    "            for param, value in metrics['best_params'].items():\n",
    "                print(f\"  {param}: {value}\")\n",
    "\n",
    "if results_prob:\n",
    "    print(\"\\nClaim Probability Models:\")\n",
    "    for name, metrics in results_prob.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"AUC = {metrics['AUC']:.4f}, Accuracy = {metrics['Accuracy']:.4f}\")\n",
    "        print(\"Best Parameters:\")\n",
    "        for param, value in metrics['best_params'].items():\n",
    "            print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4071f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ad990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
